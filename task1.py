{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10218188,"sourceType":"datasetVersion","datasetId":6316366},{"sourceId":10218216,"sourceType":"datasetVersion","datasetId":6316391}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-16T15:59:36.776358Z\",\"iopub.execute_input\":\"2024-12-16T15:59:36.776610Z\",\"iopub.status.idle\":\"2024-12-16T15:59:45.026437Z\",\"shell.execute_reply.started\":\"2024-12-16T15:59:36.776584Z\",\"shell.execute_reply\":\"2024-12-16T15:59:45.025355Z\"}}\n%pip install ultralytics supervision roboflow\nimport ultralytics\nultralytics.checks()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-16T16:12:39.169089Z\",\"iopub.execute_input\":\"2024-12-16T16:12:39.169687Z\",\"iopub.status.idle\":\"2024-12-16T16:12:50.388798Z\",\"shell.execute_reply.started\":\"2024-12-16T16:12:39.169652Z\",\"shell.execute_reply\":\"2024-12-16T16:12:50.387888Z\"}}\nfrom ultralytics import YOLO\n\nmodel = YOLO(\"yolo\") \n\nresults = model([\"/kaggle/input/testimages/1.jpg\", \"/kaggle/input/testimages/2.jpg\",\"/kaggle/input/testimages/3.jpg\"] , save_txt =True)  # return a list of Results objects\n\nfor result in results:\n    boxes = result.boxes  \n    masks = result.masks  \n    keypoints = result.keypoints  \n    probs = result.probs \n    obb = result.obb  \n    result.show()  \n    result.save(filename=\"result.jpg\")  \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-16T16:16:55.357923Z\",\"iopub.execute_input\":\"2024-12-16T16:16:55.358558Z\",\"iopub.status.idle\":\"2024-12-16T16:16:55.362619Z\",\"shell.execute_reply.started\":\"2024-12-16T16:16:55.358524Z\",\"shell.execute_reply\":\"2024-12-16T16:16:55.361720Z\"}}\nimport os\nimport pandas as pd\nimport google.generativeai as genai\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-16T16:17:00.681239Z\",\"iopub.execute_input\":\"2024-12-16T16:17:00.681911Z\",\"iopub.status.idle\":\"2024-12-16T16:17:00.685876Z\",\"shell.execute_reply.started\":\"2024-12-16T16:17:00.681877Z\",\"shell.execute_reply\":\"2024-12-16T16:17:00.685012Z\"}}\nos.environ['GOOGLE_API_KEY'] = \"AIzaSyChBv6GV_pRT19QEKcsQCW7hnC2pOI2r8E\"\ngenai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-16T16:17:06.662126Z\",\"iopub.execute_input\":\"2024-12-16T16:17:06.662796Z\",\"iopub.status.idle\":\"2024-12-16T16:17:06.666616Z\",\"shell.execute_reply.started\":\"2024-12-16T16:17:06.662763Z\",\"shell.execute_reply\":\"2024-12-16T16:17:06.665769Z\"}}\ngemini = genai.GenerativeModel('gemini-pro')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-16T16:25:50.967092Z\",\"iopub.execute_input\":\"2024-12-16T16:25:50.967446Z\",\"iopub.status.idle\":\"2024-12-16T16:25:52.560269Z\",\"shell.execute_reply.started\":\"2024-12-16T16:25:50.967415Z\",\"shell.execute_reply\":\"2024-12-16T16:25:52.559436Z\"}}\nfrom ultralytics import YOLO\n\nmodel = YOLO(\"yolo11s.pt\")  \n\nresults = model([\"/kaggle/input/testimages/1.jpg\", \"/kaggle/input/testimages/2.jpg\",\"/kaggle/input/testimages/3.jpg\"] , save_txt =True)  # return a list of Results objects\n\nfor i, result in enumerate(results):\n    boxes = result.boxes \n    masks = result.masks  \n    keypoints = result.keypoints \n    probs = result.probs  \n    obb = result.obb \n    result.show()  \n    result.save(filename=\"result.jpg\")  \n    \n    class_ids = boxes.cls  \n\n    output_filename = f\"//kaggle/working/image_{i+1}_labels.txt\"\n    with open(output_filename, \"w\") as file:\n        file.write(f\"Detected objects in image {i+1}:\\n\")\n        \n        for class_id in class_ids:\n            class_name = result.names[int(class_id)] \n            file.write(f\"{class_name}\\n\") \n    print(f\"Detected objects in image {i+1} saved to {output_filename}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-12-16T17:00:31.890442Z\",\"iopub.execute_input\":\"2024-12-16T17:00:31.890826Z\",\"iopub.status.idle\":\"2024-12-16T17:00:37.225035Z\",\"shell.execute_reply.started\":\"2024-12-16T17:00:31.890797Z\",\"shell.execute_reply\":\"2024-12-16T17:00:37.224146Z\"}}\ndef process_labels_from_file(file_path):\n    \n    with open(file_path, \"r\") as file:\n        lines = file.readlines()\n\n    labels = [line.strip() for line in lines if line.strip()]\n    data_string = \"\\n\".join(labels)\n    return data_string\n\ndef generate_caption_for_image(data_string, keyword=None):\n    \"\"\"\n    Generates a detailed caption based on the provided object labels for Gemini,\n    with an optional keyword to modify the caption's context.\n    \"\"\"\n    # If a keyword is provided, include it in the prompt\n    if keyword:\n        context_string = f\"Consider that the context of this image is '{keyword}'. \"\n    else:\n        context_string = \"Generate a detailed caption based on the objects detected in the image.\"\n\n    # Construct the prompt\n    prompt = f\"\"\"\n    You are an assistant tasked with generating a detailed and context-rich caption based on the detected objects in the image.\n    The data below contains the list of detected objects along with their class names:\n\n    {data_string}\n\n    {context_string}\n\n    Based on this information, generate a detailed caption describing the image in a natural and informative way.\n    \"\"\"\n\n    # Assuming you have the Gemini model set up\n    response = gemini.generate_content(prompt)\n    return response.text\n\nfile_paths = [\"/kaggle/working/image_1_labels.txt\", \"/kaggle/working/image_2_labels.txt\", \"/kaggle/working/image_3_labels.txt\"]\n\ngenerated_captions = []\n\nfor file_path in file_paths:\n    data_string = process_labels_from_file(file_path)\n    \n    caption = generate_caption_for_image(data_string , keyword = \"cozy\")\n    \n    generated_captions.append(caption)\n\n    print(f\"Generated Caption for {file_path}:\")\n    print(caption)\n    print(\"=\" * 50)\n","metadata":{"_uuid":"881de882-6ded-4925-a832-c0ac458bc1b2","_cell_guid":"a9adac26-62f9-4fea-8ec5-894e20b15f5a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}