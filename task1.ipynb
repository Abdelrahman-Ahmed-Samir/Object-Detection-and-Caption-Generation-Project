{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10218188,"sourceType":"datasetVersion","datasetId":6316366},{"sourceId":10218216,"sourceType":"datasetVersion","datasetId":6316391}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install ultralytics supervision roboflow\nimport ultralytics\nultralytics.checks()","metadata":{"_uuid":"e4d0b8b6-7557-4b5b-b892-9874c133f400","_cell_guid":"d5233b42-8d00-469a-8a01-b0bce5d02929","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T15:59:36.776358Z","iopub.execute_input":"2024-12-16T15:59:36.776610Z","iopub.status.idle":"2024-12-16T15:59:45.026437Z","shell.execute_reply.started":"2024-12-16T15:59:36.776584Z","shell.execute_reply":"2024-12-16T15:59:45.025355Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport google.generativeai as genai","metadata":{"_uuid":"67d4c298-202f-4085-9500-f8d574f8fce9","_cell_guid":"70085811-a44d-438e-9b95-54b227cdce39","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T16:16:55.357923Z","iopub.execute_input":"2024-12-16T16:16:55.358558Z","iopub.status.idle":"2024-12-16T16:16:55.362619Z","shell.execute_reply.started":"2024-12-16T16:16:55.358524Z","shell.execute_reply":"2024-12-16T16:16:55.361720Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.environ['GOOGLE_API_KEY'] = \"AIzaSyChBv6GV_pRT19QEKcsQCW7hnC2pOI2r8E\"\ngenai.configure(api_key=os.environ['GOOGLE_API_KEY'])","metadata":{"_uuid":"de739a45-1663-465c-9cf9-7e5f1a0074a7","_cell_guid":"fc1cec40-8cb1-4b9e-949e-77c50bbba454","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T16:17:00.681239Z","iopub.execute_input":"2024-12-16T16:17:00.681911Z","iopub.status.idle":"2024-12-16T16:17:00.685876Z","shell.execute_reply.started":"2024-12-16T16:17:00.681877Z","shell.execute_reply":"2024-12-16T16:17:00.685012Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gemini = genai.GenerativeModel('gemini-pro')","metadata":{"_uuid":"6d536bb3-8344-4129-868a-6ac06a18f057","_cell_guid":"045e94ef-8c40-46d1-86d2-f3bccd3f4a92","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T16:17:06.662126Z","iopub.execute_input":"2024-12-16T16:17:06.662796Z","iopub.status.idle":"2024-12-16T16:17:06.666616Z","shell.execute_reply.started":"2024-12-16T16:17:06.662763Z","shell.execute_reply":"2024-12-16T16:17:06.665769Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(\"yolo11s.pt\")  \n\nresults = model([\"/kaggle/input/testimages/1.jpg\", \"/kaggle/input/testimages/2.jpg\",\"/kaggle/input/testimages/3.jpg\"] , save_txt =True)  # return a list of Results objects\n\nfor i, result in enumerate(results):\n    boxes = result.boxes \n    masks = result.masks  \n    keypoints = result.keypoints \n    probs = result.probs  \n    obb = result.obb \n    result.show()  \n    result.save(filename=\"result.jpg\")  \n    \n    class_ids = boxes.cls  \n\n    output_filename = f\"//kaggle/working/image_{i+1}_labels.txt\"\n    with open(output_filename, \"w\") as file:\n        file.write(f\"Detected objects in image {i+1}:\\n\")\n        \n        for class_id in class_ids:\n            class_name = result.names[int(class_id)] \n            file.write(f\"{class_name}\\n\") \n    print(f\"Detected objects in image {i+1} saved to {output_filename}\")","metadata":{"_uuid":"233e4e7f-930f-4481-8ee9-6e30662cfa95","_cell_guid":"6fc897d5-22ca-4029-8cd2-4685e03058f5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T17:23:47.968111Z","iopub.execute_input":"2024-12-16T17:23:47.968813Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\n0: 640x640 1 bench, 13.2ms\n1: 640x640 11 persons, 3 cars, 1 motorcycle, 13.2ms\n2: 640x640 1 cat, 1 bed, 1 laptop, 13.2ms\nSpeed: 3.1ms preprocess, 13.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\nResults saved to \u001b[1mruns/detect/predict4\u001b[0m\n3 labels saved to runs/detect/predict4/labels\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def process_labels_from_file(file_path):\n    \n    with open(file_path, \"r\") as file:\n        lines = file.readlines()\n\n    labels = [line.strip() for line in lines if line.strip()]\n    data_string = \"\\n\".join(labels)\n    return data_string\n\ndef generate_caption_for_image(data_string, keyword=None):\n    \"\"\"\n    Generates a detailed caption based on the provided object labels for Gemini,\n    with an optional keyword to modify the caption's context.\n    \"\"\"\n    # If a keyword is provided, include it in the prompt\n    if keyword:\n        context_string = f\"Consider that the context of this image is '{keyword}'. \"\n    else:\n        context_string = \"Generate a detailed caption based on the objects detected in the image.\"\n\n    # Construct the prompt\n    prompt = f\"\"\"\n    You are an assistant tasked with generating a detailed and context-rich caption based on the detected objects in the image.\n    The data below contains the list of detected objects along with their class names:\n\n    {data_string}\n\n    {context_string}\n\n    Based on this information, generate a detailed caption describing the image in a natural and informative way.\n    \"\"\"\n\n    # Assuming you have the Gemini model set up\n    response = gemini.generate_content(prompt)\n    return response.text\n\nfile_paths = [\"/kaggle/working/image_1_labels.txt\", \"/kaggle/working/image_2_labels.txt\", \"/kaggle/working/image_3_labels.txt\"]\n\ngenerated_captions = []\n\nfor file_path in file_paths:\n    data_string = process_labels_from_file(file_path)\n    \n    caption = generate_caption_for_image(data_string , keyword = \"cozy\")\n    \n    generated_captions.append(caption)\n\n    print(f\"Generated Caption for {file_path}:\")\n    print(caption)\n    print(\"=\" * 50)","metadata":{"_uuid":"babcc7e9-d2ed-4f19-973c-cd0786bdf347","_cell_guid":"ac44ae9d-eef3-4e32-a8c9-61989c16f467","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-16T17:00:31.890442Z","iopub.execute_input":"2024-12-16T17:00:31.890826Z","iopub.status.idle":"2024-12-16T17:00:37.225035Z","shell.execute_reply.started":"2024-12-16T17:00:31.890797Z","shell.execute_reply":"2024-12-16T17:00:37.224146Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}